/*
 ============================================================================
 Name        : adaboost.c
 Author      : Daniel Mårtensson
 Version     : 1.0
 Copyright   : MIT
 Description : Train an adaboost model
 ============================================================================
 */

#include "CControl/ccontrol.h"

#define row 50
#define column 2

int main() {
	clock_t start, end;
	float cpu_time_used;
	start = clock();

	/* Create data */
	float X_train[row * column] = {
   0.244502,   0.145355,
   1.110587,   0.680469,
   2.040559, -0.463272,
   2.372711, -0.882711,
   1.616324,   0.105912,
   1.400971,   0.870300,
   1.023016,   0.614341,
   2.400894, -0.775256,
   0.157173,   0.077490,
   1.655935, -0.050421,
   1.553522,   0.278198,
   1.097030,   0.780508,
   2.372828, -0.552003,
   2.861700, -1.097160,
   1.481408,   0.132273,
   2.758335, -1.082694,
   2.355643, -0.678449,
   0.228124,   0.088516,
   1.819973, -0.058473,
   1.047095,   1.178790,
   2.279378, -0.463483,
   2.115302, -0.426430,
   0.428084,   0.620711,
   1.335476,   0.420418,
   1.230981,   0.817455,
   1.017220,   0.546925,
   1.669851,   1.127024,
   0.687856,   0.776910,
   0.660303,   0.892912,
   1.717766, -0.047478,
   0.603546,   0.573293,
   0.845042,   1.328609,
   1.055791,   0.953903,
   0.768528,   0.635114,
   0.706911,   0.520891,
   2.884487, -1.326102,
   1.249675,   1.045280,
   0.699192,   0.613131,
   2.015088, -0.543831,
   1.279807,   0.115933,
   2.697030, -0.710368,
   2.052557, -0.306448,
   1.719568,   1.053420,
   1.364346,   1.125595,
   1.339962,   1.239389,
   0.350487, -0.142431,
   1.510210,   0.135239,
   1.239728,   1.122342,
   2.963414, -0.857878,
   0.592496,   0.455147 };

	float y_train[row] = {
	 1,
   -1,
   -1,
   -1,
   -1,
	1,
	1,
   -1,
	1,
   -1,
   -1,
   -1,
   -1,
   -1,
   -1,
   -1,
   -1,
	1,
   -1,
	1,
   -1,
   -1,
	1,
   -1,
	1,
   -1,
	1,
	1,
	1,
   -1,
	1,
	1,
   -1,
	1,
	1,
   -1,
	1,
	1,
   -1,
   -1,
   -1,
   -1,
	1,
	1,
	1,
	1,
   -1,
	1,
   -1,
	1 };

	float X_test[row * column] = {
	2.984666, -0.871231,
	1.299282,   0.811124,
	2.490065, -0.875538,
	2.934055, -1.105015,
	1.795833, -0.357223,
	0.556731,   0.811384,
	1.136348,   1.021250,
	1.059996,   0.960588,
	1.175014,   1.194191,
	0.306644,   0.371325,
	2.863285, -0.851170,
	0.541112,   0.710946,
	1.284122,   0.311120,
	0.429304,   0.213141,
	0.213378,   0.216083,
	1.610738,   1.022333,
	1.279571,   0.124259,
	2.099431, -0.678321,
	0.051029, -0.070328,
	0.438557,   0.437273,
	0.604765,   0.228577,
	2.730641, -0.804946,
	2.581530, -1.025855,
	0.215045,   0.324767,
	2.876525, -1.089302,
	1.167649,   0.465319,
	1.500063,   1.102706,
	1.251622,   0.441579,
	0.193742, -0.073065,
	1.924254, -0.217111,
	1.560809,   0.944003,
	1.024698,   0.829349,
	2.120391, -0.652540,
	1.085447,   0.653045,
	0.380428,   0.534305,
	0.556919,   0.229393,
	1.560877,   0.875385,
	1.068931,   0.829418,
	2.008937, -0.434468,
	1.017749,   0.586184,
	1.810329,   1.111023,
	1.413824,   1.003598,
	1.152095,   0.459541,
	0.806252,   0.743291,
	1.304802,   0.869761,
	2.308975, -0.696251,
	1.292584,   1.124175,
	2.733209, -0.967864,
	2.671475, -0.576967,
	1.908365, -0.374568 };

	float y_test[row] = {
   -1,
	1,
   -1,
   -1,
   -1,
	1,
	1,
	1,
	1,
	1,
   -1,
	1,
   -1,
	1,
	1,
	1,
   -1,
   -1,
	1,
	1,
	1,
   -1,
   -1,
	1,
   -1,
   -1,
	1,
   -1,
	1,
   -1,
	1,
	1,
   -1,
   -1,
	1,
	1,
	1,
	1,
   -1,
	1,
	1,
	1,
   -1,
	1,
	1,
   -1,
	1,
   -1,
   -1,
   -1
	};

	/* Train AdaBoost model */
	size_t N = 3;
	ADABOOST_MODEL* models = adaboost_train(X_train, y_train, N, row, column);

	/* Evaluate the model */
	float accuracy = adaboost_eval(models, X_test, y_test, N, row, column);

	/* Print */
	printf("Accuracy: %f\n", accuracy);

	/* Predict class - Notice that the feature index inside models cannot exceed the index of X_test, in this case "column" */
	printf("Class id: %i\n", adaboost_predict(models, &X_test[4 * column], N));

	/* Free */
	free(models);

	/* Detect memory leak */
	detectmemoryleak();

	end = clock();
	cpu_time_used = ((float)(end - start)) / CLOCKS_PER_SEC;
	printf("\nTotal speed  was %f\n", cpu_time_used);

	return EXIT_SUCCESS;
}

/* GNU Octave code
close all
clear all

% Give the if-statement true and very nonlinar data is used, else, Fisher's Iris flower set is used
if(true)
  % Amount of rows
  numRows = 150;

  % Total Columns
  numColumns = 2;

  % Create a matrix of zeros for X and a vector of zeros for y
  X = zeros(numRows, numColumns);
  y = zeros(numRows, 1);

  % Create data for class 1 (non-linear function + noise)
  class1_x1 = 2 * rand(numRows/2, 1);  % Noise function
  class1_x2 = sin(class1_x1) + 0.2 * randn(numRows/2, 1);  % Nonlinear function with noise
  class1 = [class1_x1, class1_x2];
  y(1:numRows/2) = 1;  % Labels for class 1

  % Create data for class 2 (non-linear function + noise)
  class2_x1 = 2 * rand(numRows/2, 1) + 1;  % Noise
  class2_x2 = cos(class2_x1) + 0.2 * randn(numRows/2, 1);  % Nonlinear function with noise
  class2 = [class2_x1, class2_x2];
  y(numRows/2 + 1:end) = -1;  % Labels for class 2

  % Combine the data to create the final matrix X
  X(1:numRows/2, :) = class1;
  X(numRows/2 + 1:end, :) = class2;

  % Plot
  scatter(X(y == -1, 1), X(y == -1, 2));
  hold on
  scatter(X(y == 1, 1), X(y == 1, 2));
else
  % Load the Fisher's Iris data set
  data = load('fisheriris.mat');
  X = data.meas;
  y = strcmp(data.species,'setosa') * 2 - 1;
end

% Important to do shuffle!
s = randperm(150, 150)';
X = X(s, :);
y = y(s);

% Create train and test data
X_train = X(1:50, :);
y_train = y(1:50);
X_test = X(101:end, :);
y_test = y(101:end);

X_train = [
 0.244502,   0.145355,
 1.110587,   0.680469,
 2.040559, - 0.463272,
 2.372711, - 0.882711,
 1.616324,   0.105912,
 1.400971,   0.870300,
 1.023016,   0.614341,
 2.400894, - 0.775256,
 0.157173,   0.077490,
 1.655935, - 0.050421,
 1.553522,   0.278198,
 1.097030,   0.780508,
 2.372828, - 0.552003,
 2.861700, - 1.097160,
 1.481408,   0.132273,
 2.758335, - 1.082694,
 2.355643, - 0.678449,
 0.228124,   0.088516,
 1.819973, - 0.058473,
 1.047095,   1.178790,
 2.279378, - 0.463483,
 2.115302, - 0.426430,
 0.428084,   0.620711,
 1.335476,   0.420418,
 1.230981,   0.817455,
 1.017220,   0.546925,
 1.669851,   1.127024,
 0.687856,   0.776910,
 0.660303,   0.892912,
 1.717766, - 0.047478,
 0.603546,   0.573293,
 0.845042,   1.328609,
 1.055791,   0.953903,
 0.768528,   0.635114,
 0.706911,   0.520891,
 2.884487, - 1.326102,
 1.249675,   1.045280,
 0.699192,   0.613131,
 2.015088, - 0.543831,
 1.279807,   0.115933,
 2.697030, - 0.710368,
 2.052557, - 0.306448,
 1.719568,   1.053420,
 1.364346,   1.125595,
 1.339962,   1.239389,
 0.350487, - 0.142431,
 1.510210,   0.135239,
 1.239728,   1.122342,
 2.963414, - 0.857878,
 0.592496,   0.455147 ];

y_train = [
	1,
- 1,
- 1,
- 1,
- 1,
 1,
 1,
- 1,
 1,
- 1,
- 1,
- 1,
- 1,
- 1,
- 1,
- 1,
- 1,
 1,
- 1,
 1,
- 1,
- 1,
 1,
- 1,
 1,
- 1,
 1,
 1,
 1,
- 1,
 1,
 1,
- 1,
 1,
 1,
- 1,
 1,
 1,
- 1,
- 1,
- 1,
- 1,
 1,
 1,
 1,
 1,
- 1,
 1,
- 1,
 1 ];

X_test = [
 2.984666, -0.871231,
 1.299282,   0.811124,
 2.490065, -0.875538,
 2.934055, -1.105015,
 1.795833, -0.357223,
 0.556731,   0.811384,
 1.136348,   1.021250,
 1.059996,   0.960588,
 1.175014,   1.194191,
 0.306644,   0.371325,
 2.863285, -0.851170,
 0.541112,   0.710946,
 1.284122,   0.311120,
 0.429304,   0.213141,
 0.213378,   0.216083,
 1.610738,   1.022333,
 1.279571,   0.124259,
 2.099431, -0.678321,
 0.051029, -0.070328,
 0.438557,   0.437273,
 0.604765,   0.228577,
 2.730641, -0.804946,
 2.581530, -1.025855,
 0.215045,   0.324767,
 2.876525, -1.089302,
 1.167649,   0.465319,
 1.500063,   1.102706,
 1.251622,   0.441579,
 0.193742, -0.073065,
 1.924254, -0.217111,
 1.560809,   0.944003,
 1.024698,   0.829349,
 2.120391, -0.652540,
 1.085447,   0.653045,
 0.380428,   0.534305,
 0.556919,   0.229393,
 1.560877,   0.875385,
 1.068931,   0.829418,
 2.008937, -0.434468,
 1.017749,   0.586184,
 1.810329,   1.111023,
 1.413824,   1.003598,
 1.152095,   0.459541,
 0.806252,   0.743291,
 1.304802,   0.869761,
 2.308975, -0.696251,
 1.292584,   1.124175,
 2.733209, -0.967864,
 2.671475, -0.576967,
 1.908365, -0.374568];

y_test = [
-1,
 1,
-1,
-1,
-1,
 1,
 1,
 1,
 1,
 1,
-1,
 1,
-1,
 1,
 1,
 1,
-1,
-1,
 1,
 1,
 1,
-1,
-1,
 1,
-1,
-1,
 1,
-1,
 1,
-1,
 1,
 1,
-1,
-1,
 1,
 1,
 1,
 1,
-1,
 1,
 1,
 1,
-1,
 1,
 1,
-1,
 1,
-1,
-1,
-1];

% Adaboost classification with N weak classifiers
N = 5;
[models, accuracy, activation_function] = mi.adaboost(X_train, X_test, y_train, y_test, N);

for i = 1:N
  models{i}.alpha
end

% This is how the class id is found from one randomly selected row from X_test
class_id = activation_function(models, X_test(5, :))
fprintf('Accuracy AdaBoost: %.2f%%\n', accuracy * 100);
return

% Compare the accuracy with the neural networks Neural network - One layer
C = 1;
lambda = 1;
X_train = X([1:20 51:70 101:120], :);
y_train = y([1:20 51:70 101:120]);
X_test = X([21:50 71:100 121:150], :);
y_test = y([21:50 71:100 121:150]);
[weight, bias, activation_function] = mi.nn(X_train, y_train, C, lambda);

% Validate
class_ids = sign(X_test*weight' + bias);
accuracy = sum(y_test == class_ids) / length(y_test);
fprintf('Accuracy Neural Network: %.2f%%\n', accuracy * 100);

*/