/*
 ============================================================================
 Name        : sfaod.c
 Author      : Daniel Mårtensson
 Version     : 1.0
 Copyright   : MIT
 Description : Train and classify images
 ============================================================================
 */

#include "CControl/ccontrol.h"

int main() {
	clock_t start, end;
	float cpu_time_used;
	start = clock();

	/* Create SFA parameter struct */
	MODEL_SETTINGS model_settings;
	model_settings.data_settings_sfa.settings_general.save_model = true;

	/* Select data and what to do */
	strcpy(model_settings.data_settings_sfa.settings_general.folder_path, "..\\src\\CControl\\Documents\\Data\\yale");

	/*
	 * Object detection:
	 * This algoritm is using feature points from F.A.S.T algorithm.
	 */
	model_settings.data_settings_sfa.settings_sfa.fast_method = FAST_METHOD_9;
	model_settings.data_settings_sfa.settings_sfa.fast_threshold = 50;

	/*
	 * Remove outliers from the data:
	 * epsilon is the outliers radius
	 * min_pts is the minimum points for a cluster
	 */
	model_settings.data_settings_sfa.settings_general.remove_outliers = false;
	model_settings.data_settings_sfa.settings_general.epsilon = 500;
	model_settings.data_settings_sfa.settings_general.min_pts = 3;

	/*
	 * Kernel PCA configuration:
	 * The variable components_pca is a tuning parameter.
	 * Keep that large, but not so large so PCA will include garbage values into your traing data
	 * I'm using about components_pca = 100 for Yale dataset. A good rule of thump is not use more than total images you have in your folders.
	 * The array kernel_parameters is for nonlinear kernels. Some nonlinear kernels only need 1 parameters, some want more.
	 */
	model_settings.data_settings_sfa.settings_general.components_pca = 100;
	model_settings.data_settings_sfa.settings_general.kernel_parameters[0] = 0.0000001f;
	model_settings.data_settings_sfa.settings_general.kernel_method = KERNEL_METHOD_RBF;

	/*
	 * Neural network configuration:
	 * This neural network is build by support vector machines. The C hyperparameter tells the SVM optimization how much you want to avoid misclassifying each training example.
	 * For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly.
	 * Conversely, a very small value of C will cause the optimizer to look for a larger-margin separating hyperplane,
	 * even if that hyperplane misclassifies more points. For very tiny values of C, you should get misclassified examples, often even if your training data is linearly separable.
	 * Lambda is regularization for the SVM. Large lambda value makes it faster to optimize, with less accuracy.
	 */
	model_settings.data_settings_sfa.settings_general.C = 1.0f;
	model_settings.data_settings_sfa.settings_general.lambda = 2.5f;

	/* Fisherfaces training */
	MODEL* model = sfaod(&model_settings);

	/* Here is the model parameters */
	printf("\nBias b parameters with size %i x 1\n", model->sfa_model.model_row[0]);
	print(model->sfa_model.model_b[0], model->sfa_model.model_row[0], 1);
	printf("\nWeight W parameters have the size %i x %i\n", model->sfa_model.model_row[0], model->sfa_model.model_column[0]);
	printf("Use the function nn_predict to predict the class ID\n");

	/* Free */
	imcollectfree(model);

	/* Memory leak */
	detectmemoryleak();

	end = clock();
	cpu_time_used = ((float)(end - start)) / CLOCKS_PER_SEC;
	printf("\nTotal speed  was %f\n", cpu_time_used);
	return EXIT_SUCCESS;
}